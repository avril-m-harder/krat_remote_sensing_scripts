save$dep.var <- 'num.surv'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'max.age'){
gbm.var.test <- gbm(
formula = max.age ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'max.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'avg.age'){
gbm.var.test <- gbm(
formula = avg.age ~ .,
distribution = "gaussian",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'avg.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
rd <- rd + 1
}
View(TOP.VARS)
##### 4. Test out strength of top variables with permutations #####
## Below, I'm running
TESTVARS <- NULL
sets <- as.data.frame(cbind(c('num.surv','num.off','max.age','avg.age'), c(numsurv.i, numoff.i, maxage.i, avgage.i)))
sets[,2] <- as.numeric(sets[,2])
pred.dat <- all.dat[,c(9:ncol(all.dat))]
# pdf('/Users/Avril/Desktop/test_var_tests.pdf', height=10, width=6)
rd <- 1
while(rd <= 50){ ## run it 50 times
print(paste0('-------> ',rd))
for(d in 1:nrow(sets)){
temp <- TOP.VARS[TOP.VARS$dep.var == sets[d,1],]
temp <- temp[order(-temp$rel.inf),]
top.two <- pred.dat[, colnames(pred.dat) %in% temp$var[1:2]]     ## get top two influential variables from full model
not.top.ten <- pred.dat[,colnames(pred.dat) %notin% temp$var]    ## get list of variables not in top ten relative influence values
## identify which variables are not correlated with the top two variables
cors.1 <- abs(cor(top.two[,1], not.top.ten))[1,]
cors.1 <- cors.1[cors.1 < 0.3]
cors.2 <- abs(cor(top.two[,2], not.top.ten))[1,]
cors.2 <- cors.2[cors.2 < 0.3]
other.vars <- names(cors.1)[names(cors.1) %in% names(cors.2)]
## sample 10 variables (these may be correlated with one another, should maybe account for that?)
other.vars <- sample(other.vars, 10)
## create new dataframe and run model on this
new.dat <- all.dat[,c(sets[d,1], colnames(top.two), other.vars)]
new.dat <- new.dat[!is.na(new.dat[,1]),]
if(sets[d,1] == 'num.off'){
gbm.var.test <- gbm(
formula = num.off ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'num.off'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'num.surv'){
gbm.var.test <- gbm(
formula = num.surv ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'num.surv'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'max.age'){
gbm.var.test <- gbm(
formula = max.age ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'max.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'avg.age'){
gbm.var.test <- gbm(
formula = avg.age ~ .,
distribution = "gaussian",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'avg.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
rd <- rd + 1
}
# dev.off()
test.vars <- TESTVARS
head(all.dat)
##### 4. Test out strength of top variables with permutations #####
## Below, I'm running
TESTVARS <- NULL
sets <- as.data.frame(cbind(c('num.surv','num.off','max.age','avg.age'), c(numsurv.i, numoff.i, maxage.i, avgage.i)))
sets[,2] <- as.numeric(sets[,2])
pred.dat <- all.dat[,c(8:ncol(all.dat))]
# pdf('/Users/Avril/Desktop/test_var_tests.pdf', height=10, width=6)
rd <- 1
while(rd <= 50){ ## run it 50 times
print(paste0('-------> ',rd))
for(d in 1:nrow(sets)){
temp <- TOP.VARS[TOP.VARS$dep.var == sets[d,1],]
temp <- temp[order(-temp$rel.inf),]
top.two <- pred.dat[, colnames(pred.dat) %in% temp$var[1:2]]     ## get top two influential variables from full model
not.top.ten <- pred.dat[,colnames(pred.dat) %notin% temp$var]    ## get list of variables not in top ten relative influence values
## identify which variables are not correlated with the top two variables
cors.1 <- abs(cor(top.two[,1], not.top.ten))[1,]
cors.1 <- cors.1[cors.1 < 0.3]
cors.2 <- abs(cor(top.two[,2], not.top.ten))[1,]
cors.2 <- cors.2[cors.2 < 0.3]
other.vars <- names(cors.1)[names(cors.1) %in% names(cors.2)]
## sample 10 variables (these may be correlated with one another, should maybe account for that?)
other.vars <- sample(other.vars, 10)
## create new dataframe and run model on this
new.dat <- all.dat[,c(sets[d,1], colnames(top.two), other.vars)]
new.dat <- new.dat[!is.na(new.dat[,1]),]
if(sets[d,1] == 'num.off'){
gbm.var.test <- gbm(
formula = num.off ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'num.off'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'num.surv'){
gbm.var.test <- gbm(
formula = num.surv ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'num.surv'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'max.age'){
gbm.var.test <- gbm(
formula = max.age ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'max.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'avg.age'){
gbm.var.test <- gbm(
formula = avg.age ~ .,
distribution = "gaussian",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'avg.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
rd <- rd + 1
}
other.vars
##### 4. Test out strength of top variables with permutations #####
## Below, I'm running
TESTVARS <- NULL
sets <- as.data.frame(cbind(c('num.surv','num.off','max.age','avg.age'), c(numsurv.i, numoff.i, maxage.i, avgage.i)))
sets[,2] <- as.numeric(sets[,2])
pred.dat <- all.dat[,c(8:ncol(all.dat))]
# pdf('/Users/Avril/Desktop/test_var_tests.pdf', height=10, width=6)
rd <- 1
while(rd <= 50){ ## run it 50 times
print(paste0('-------> ',rd))
for(d in 1:nrow(sets)){
temp <- TOP.VARS[TOP.VARS$dep.var == sets[d,1],]
temp <- temp[order(-temp$rel.inf),]
top.two <- pred.dat[, colnames(pred.dat) %in% temp$var[1:2]]     ## get top two influential variables from full model
not.top.ten <- pred.dat[,colnames(pred.dat) %notin% temp$var]    ## get list of variables not in top ten relative influence values
## identify which variables are not correlated with the top two variables
cors.1 <- abs(cor(top.two[,1], not.top.ten))[1,]
cors.1 <- cors.1[cors.1 < 0.3]
cors.2 <- abs(cor(top.two[,2], not.top.ten))[1,]
cors.2 <- cors.2[cors.2 < 0.3]
other.vars <- names(cors.1)[names(cors.1) %in% names(cors.2)]
## sample 10 variables (these may be correlated with one another, should maybe account for that?)
# other.vars <- sample(other.vars, 10)
## create new dataframe and run model on this
new.dat <- all.dat[,c(sets[d,1], colnames(top.two), other.vars)]
new.dat <- new.dat[!is.na(new.dat[,1]),]
if(sets[d,1] == 'num.off'){
gbm.var.test <- gbm(
formula = num.off ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'num.off'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'num.surv'){
gbm.var.test <- gbm(
formula = num.surv ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'num.surv'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'max.age'){
gbm.var.test <- gbm(
formula = max.age ~ .,
distribution = "poisson",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'max.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
if(sets[d,1] == 'avg.age'){
gbm.var.test <- gbm(
formula = avg.age ~ .,
distribution = "gaussian",
data = new.dat,
n.trees = 5000,
interaction.depth = hyper.grid$interaction.depth[sets[d,2]],
shrinkage = hyper.grid$shrinkage[sets[d,2]],
bag.fraction = 0.5,
cv.folds = 5,
n.cores = 1)
save <- summary(gbm.var.test)
rownames(save) <- NULL
save$dep.var <- 'avg.age'
save$iter <- rd
TESTVARS <- rbind(TESTVARS, save)
}
rd <- rd + 1
}
??spectralIndices
library(shiny)
## Good overview: https://datasciencegenie.com/how-to-embed-a-shiny-app-on-website/
library(shiny)
# Define UI for application that draws a histogram
ui <- fluidPage(
sidebarLayout(
sidebarPanel(sliderInput("samplesize","Sample Size:",min = 100,max = 10000,value = 1000)),
mainPanel(plotOutput("distPlot"))
)
# Define server logic required to draw a histogram
server <- function(input, output) {
output$distPlot <- renderPlot({
hist(rnorm(input$samplesize),col='darkorchid',xlab="Sample",main="Standard Normally Distributed Sample")},
height=300
)
}
# Run the application
shinyApp(ui = ui, server = server)
library(sp)
library(raster)
library(RStoolbox)
library(viridis)
library(ggplot2)
library(scales)
options("rgdal_show_exportToProj4_warnings"="none")
library(rgdal)
library(TeachingDemos)
library(reshape2)
library(ggplot2)
`%notin%` <- Negate(`%in%`)
## read in remote sensing predictor variables
tc.fn <- 'tc_manual_cloudcheck' ## for TC data -- tc_manual_cloudcheck
tc.dat <- read.csv(paste0('/Users/Avril/Documents/krat_remote_sensing/C2L2_tc_output_tables/C2L2_',tc.fn,'.csv'))
tc.dat$year <- do.call(rbind, strsplit(tc.dat$acq.date, split='-', fixed=TRUE))[,1]
tc.dat$year <- as.numeric(tc.dat$year)
tc.dat$month <- do.call(rbind, strsplit(tc.dat$acq.date, split='-', fixed=TRUE))[,2]
tc.dat$month <- as.numeric(tc.dat$month)
## create month index for easier identification of lag periods
tc.dat$month.index <- ((tc.dat$year-1) * 12) + tc.dat$month
head(tc.dat)
length(unique(tc.dat$scene.id))
## Examine predictor variable correlations
## (pretty heatmap plotting of correlations: http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization )
inds <- c(2:(grep('acq.date', colnames(tc.dat))-1)) ## get column numbers for remote sensing index data
cors <- round(cor(tc.dat[,inds]), 2)
## NA values for EVI2, MNDWI, NBRI, NDWI2 and TVI, so get rid of those
inds <- inds[inds %notin% c(which(colnames(tc.dat) == 'EVI2'), which(colnames(tc.dat) == 'MNDWI'),
which(colnames(tc.dat) == 'NBRI'), which(colnames(tc.dat) == 'NDWI2'),
which(colnames(tc.dat) == 'TVI'))]
## check again
cors <- round(cor(tc.dat[,inds]), 2) ## lots of highly correlated variables, but just keeping them for now I guess
## remove EVI2 and TVI from data set
tc.dat <- tc.dat[,-c(which(colnames(tc.dat) == 'EVI2'), which(colnames(tc.dat) == 'MNDWI'),
which(colnames(tc.dat) == 'NBRI'), which(colnames(tc.dat) == 'NDWI2'),
which(colnames(tc.dat) == 'TVI'))]
## get column indices for final set of remote sensing data
inds <- c(2:(grep('acq.date', colnames(tc.dat))-1))
library(sp)
library(raster)
library(RStoolbox)
library(viridis)
library(ggplot2)
library(scales)
options("rgdal_show_exportToProj4_warnings"="none")
library(rgdal)
library(TeachingDemos)
source('/Users/Avril/Documents/krat_remote_sensing/krat_remote_sensing_scripts/c2l2readMeta.R')
`%notin%` <- Negate(`%in%`)
g.col <- 'forestgreen'
w.col <- 'deepskyblue2'
b.col <- 'tan4'
n.col <- 'turquoise4'
##### Read in population (Peter's) data #####
pop.dat <- read.csv('/Users/Avril/Documents/krat_genetics/preseq_sample_information/KRATP.csv')
## lat/long headings reversed in original file
colnames(pop.dat)[7:8] <- c('long','lat')
##### Read in more population (Janna's) data #####
j.dat <- read.csv('/Users/Avril/Documents/krats/krat_data_and_paper2/summary_allstats2_withgen_zeroes.csv')
ages <- j.dat[,c('id','birthyear','deathyear')]
ages$age <- ages$deathyear - ages$birthyear
ages <- ages[,c(1,4)]
## read in 1 cropped scene to get background image and cell #s (rows, columns)
ls5.stack <- brick('/Users/Avril/Documents/krat_remote_sensing/C2L2_cropped_landsat45tm_scenes/LT05_L2SP_035038_20020622_20200905_02_T1_CROPPED.grd')
raster::plotRGB(ls5.stack, r=3, g=2, b=1, scale=ls5.stack@data@max[c(3,2,1)], margins=FALSE)
##### Read in manual mound:cell assignments (n=26) #####
### >> also needed to re-name unique mounds that were all labeled 'R2' in the original database
man.ass <- read.csv('/Users/Avril/Documents/krat_remote_sensing/archive/sorting_out_mound_names/manual_mound_cell_assignments.csv')
## rename 'R2' mounds to match their actual locations (unique names R2.1-R2.6)
r2 <- man.ass[man.ass$terr=='R2',]
for(i in 1:nrow(r2)){
pop.dat[which(pop.dat$lat == r2$lat[i] & pop.dat$long == r2$long[i]), 'terr'] <- r2$new.db.name[i]
}
##### Read in manual mound:cell assignments (n=26) #####
### >> also needed to re-name unique mounds that were all labeled 'R2' in the original database
man.ass <- read.csv('/Users/Avril/Documents/krat_remote_sensing/sorting_out_mound_names/2021_first_round/manual_mound_cell_assignments.csv')
## rename 'R2' mounds to match their actual locations (unique names R2.1-R2.6)
r2 <- man.ass[man.ass$terr=='R2',]
for(i in 1:nrow(r2)){
pop.dat[which(pop.dat$lat == r2$lat[i] & pop.dat$long == r2$long[i]), 'terr'] <- r2$new.db.name[i]
}
##### Read in mound coordinates #####
mnd.locs <- read.csv('/Users/Avril/Documents/krat_remote_sensing/intermediate_data/mound_GPS_coords_n188.csv')
mnd.locs$ID <- 1:nrow(mnd.locs) ## add column for later matching up with TC extracted pixel values
mnd.cells <- mnd.locs[,c(4,5)] ## save ID and db.name for saving cell names later
mnd.locs <- mnd.locs[c('long','lat','database.name')] ## rearrange/rename to match man.locs below
colnames(mnd.locs)[3] <- 'terr'
coordinates(mnd.locs) <- c('long','lat') ## converts to SpatialPointsDataFrame object for plotting
proj4string(mnd.locs) <- CRS("+proj=longlat +datum=WGS84") ## still in degrees
mnd.locs <- sp::spTransform(mnd.locs, CRS("+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")) ## now in meters
### manual mound:cell assignments
man.ass <- read.csv('/Users/Avril/Documents/krat_remote_sensing/archive/sorting_out_mound_names/manual_mound_cell_assignments.csv')
### manual mound:cell assignments
man.ass <- read.csv('/Users/Avril/Documents/krat_remote_sensing/sorting_out_mound_names/2021_first_round/manual_mound_cell_assignments.csv')
man.cells <- man.ass[,c('terr','new.db.name','cell')]
man.cells[!is.na(man.cells$new.db.name), 'terr'] <- man.cells[!is.na(man.cells$new.db.name), 'new.db.name']
man.cells$ID <- c((max(mnd.cells$ID)+1):(max(mnd.cells$ID)+nrow(man.cells)))
colnames(man.cells)[1] <- 'database.name'
man.cells <- man.cells[,c('database.name','ID')]
man.locs <- as.data.frame(xyFromCell(ls5.stack, man.ass$cell))
man.locs$terr <- man.ass$terr
coordinates(man.locs) <- c('x','y') ## already in meters
proj4string(man.locs)<- CRS("+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
all.locs <- rbind(mnd.locs, man.locs)
## set extent for all analyses
lo.x <- 663500
hi.x <- 665600
lo.y <- 3497000
hi.y <- 3499750
ext <- extent(lo.x, hi.x, lo.y, hi.y)
##### Read in TC and other index results #####
## set file names to be read in
tc.fn <- 'tc_manual_cloudcheck' ## for TC data -- tc_manual_cloudcheck
mc.fn <- 'mnd_manual_cloudcheck' ## for mound/cell ID key -- mnd_manual_cloudcheck
## read in results of manual cloud checking to get list of scenes to process (results of manual cloud checking)
## read in results of checking scenes with <= 20% cloud cover
res <- read.csv('/Users/Avril/Documents/krat_remote_sensing/C2L2_landsat_5_data_overviews/C2L2_low_cloud_scenes_cloud_cover_notes.csv')
table(res$usable) ## 365 / 460 scenes checked are usable (i.e., no clouds over extent or processing errors)
res <- res[which(res$usable == 1),]
res$path <- do.call(rbind, strsplit(res$filename, split='_'))[,3]
res <- res[res$path == '035038',] ## only keep scenes from Path 35
files1 <- as.vector(res$filename)
## read in results of checking scenes with > 20% cloud cover
res <- read.csv('/Users/Avril/Documents/krat_remote_sensing/C2L2_landsat_5_data_overviews/C2L2_high_cloud_scenes_cloud_cover_notes.csv')
table(res$usable) ## 20 / 62 scenes checked are usable (i.e., no clouds over extent or processing errors)
res <- res[which(res$usable == 1),]
files2 <- as.vector(res$filename)
## combine lists of files
files <- c(files1, files2)
tc.dat <- read.csv(paste0('/Users/Avril/Documents/krat_remote_sensing/C2L2_tc_output_tables/C2L2_',tc.fn,'.csv'))
mc.key <- read.csv(paste0('/Users/Avril/Documents/krat_remote_sensing/C2L2_tc_output_tables/C2L2_',mc.fn,'.csv'))
## get list of mound:cell associations
mounds.cells.only <- mc.key[,c('database.name','cell.num')]
mounds.cells.only <- mounds.cells.only[!duplicated(mounds.cells.only),]
##### Define seasons #####
tc.dat$year <- do.call(rbind, strsplit(tc.dat$acq.date, split='-'))[,1]
## define brood-year lag months (e.g., for indivs born in 2000, lag.year would be set to 2000 for July 1999-June 2000)
## i.e., abiotic data from the months of June - May are predicting survival/fitness for indivs presumably born between those months
tc.dat$year <- as.numeric(tc.dat$year)
tc.dat$month <- do.call(rbind, strsplit(tc.dat$acq.date, split='-'))[,2]
tc.dat$month <- as.numeric(tc.dat$month)
tc.dat[which(tc.dat$month %in% c(7:12)), 'half.year.lag'] <- tc.dat[which(tc.dat$month %in% c(7:12)), 'year'] + 1
tc.dat[which(tc.dat$month %in% c(1:6)), 'half.year.lag'] <- tc.dat[which(tc.dat$month %in% c(1:6)), 'year']
tc.dat$one.year.lag <- tc.dat$year+1
### two seasonal options:
## (1) define seasons by quarters (1=spring, 2=summer, 3=fall, 4=winter)
tc.dat[which(tc.dat$month %in% c(1,2,3)), 'month.szn'] <- 1
tc.dat[which(tc.dat$month %in% c(4,5,6)), 'month.szn'] <- 2
tc.dat[which(tc.dat$month %in% c(7,8,9)), 'month.szn'] <- 3
tc.dat[which(tc.dat$month %in% c(10,11,12)), 'month.szn'] <- 4
## (2) define seasons by expected precip (1=July-August, 2=Dec-March, 0=outside these months)
tc.dat[which(tc.dat$month %in% c(7,8)), 'weather.szn'] <- 1
tc.dat[which(tc.dat$month %in% c(12,1,2,3)), 'weather.szn'] <- 2
tc.dat[which(tc.dat$month %in% c(4,5,6,9,10,11)), 'weather.szn'] <- 0
head(off)
head(tc.dat)
head(mounds.cells.only)
head(pop.dat)
table(tc.dat$path)
